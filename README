# 🧠 FeelIt - Opinion Analysis on Reddit

**FeelIt** is a web application developed as a Final Degree Project to analyze opinions on any topic collected from Reddit, presenting a summarized and clear view through sentiment analysis and highlighted comments.

---

## Reddit Opinion Extractor — Backend

This is the backend service for a Reddit opinion analysis app.
It uses FastAPI, PRAW (Reddit API), and a fine-tuned DistilBERT model to extract, filter and classify Reddit comments based on a user-provided keyword.

---

## 🧱 Project Structure

/Backend/
│
├── app/
│   ├── main.py                    ← FastAPI entrypoint
│   └── services/                  ← Core logic
│        ├── findPosts.py         ← Reddit search and CSV export
│        └── sortTitles.py        ← Filter titles using DistilBERT
│
├── models/
│   └── model_output/             ← Trained DistilBERT model
│
├── data/
│   ├── CSVfile/                  ← Raw Reddit results
│   ├── CSVfilefiltered/         ← Filtered Reddit results
│   ├── CSVsTraining/            ← Data used for model training
│   ├── ResultadosFiltered/      ← Cleaned, classified results
│   ├── ResultadosLabeled/       ← Labeled datasets
│   └── titles_dataset_expanded_pipe.txt
│
├── scripts/
│   ├── EntrenarModelo.py        ← Train DistilBERT model
│   ├── ProvarModelo.py          ← Test the trained model
│   ├── printUniqueTitles.py     ← View unique titles from dataset
│   └── sortTitles_training.py   ← Filter logic used for training
│
├── .env                         ← Contains Reddit API credentials
├── config.init                  ← Optional configuration script
├── requirements.txt             ← Python dependencies
└── README.md

---

 ## How It Works

1. A user sends a search keyword to the FastAPI backend.

2. The /api/search route triggers:
    · findPosts.py → searches Reddit and stores comments in a CSV file.
    · sortTitles.py → uses a trained DistilBERT model to filter relevant posts.

3. The filtered CSV can then be used for further sentiment analysis or visualization.

---

## How to Run (Local Development)

**1. Clone the project and create a virtual environment**
"python -m venv venv"

**2. Activate the virtual environment**
# Windows
".\venv\Scripts\activate"

**3. Install dependencies**
"pip install -r requirements.txt"

**4. Set up .env file with Reddit API credentials**
REDDIT_CLIENT_ID=your_id
REDDIT_CLIENT_SECRET=your_secret
REDDIT_USER_AGENT=your_user_agent

**5. Run the FastAPI server**
"uvicorn app.main:app --reload --port 8000"


**Backend will now be accessible at:**
`http://localhost:8000/api/search?keyword=example`

---

## Model Training & Testing

1. Train the DistilBERT model using the training data (sortTitles_training.py).
2. Test the model using the test data (ProvarModelo.py).

===================

## Data Visualization

To train and test the classifier:

1. Extract titles from labeled data:
"python scripts/printUniqueTitles.py"

2. Train the model:
"python scripts/EntrenarModelo.py"

3. Evaluate or test it:
"python scripts/ProvarModelo.py"

---

## Requirements

All required packages are listed in requirements.txt.

---

## ✨ Developed by

**Pol González Casals**  
Universitat Autònoma de Barcelona (2025)  
[LinkedIn](https://www.linkedin.com/in/pol-gonzalez-casals) · [GitHub](https://github.com/ppolsii)

